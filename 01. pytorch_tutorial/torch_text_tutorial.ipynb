{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchText\n",
    "\n",
    "- 'TorchText'는 nlp 분야에서 데이터를 불러옴과 동시에 전처리를 하는 패키지이다.\n",
    "- `Data Loader`\n",
    "- 아래 과정을 한번에 쉽게 해준다.\n",
    "    1. 토크나이징\n",
    "    2. vocab 생성\n",
    "    3. 토큰 수치화\n",
    "    4. 데이터 로더 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "순서 외우기\n",
    "1. text, label 필드 객체를 생성한다.\n",
    "2. train_data = TabularDataset(..)으로 경로에서 불러온다.\n",
    "3. .build_vocab(train_data) 단어장을 생성한다.\n",
    "4. Iterator 로 dataloader 만들기\n",
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "궁금증\n",
    "1. `dataset` vs `dataloader` \n",
    "    \n",
    "    loader 는 반복자이다. (데이터 섞고, 묶고, 병렬처리하고..)\n",
    "    \n",
    "\n",
    "2. 결과값은 `vocab`과 `dataloader`인가?\n",
    "    \n",
    "   그런듯?\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용방법\n",
    "#### 1. 필드 지정 (Create Field)\n",
    "- 필드란? 텐서로 표현되는 텍스트 데이터 타입을 처리하는 객체이다.\n",
    "- 각 토큰을 숫자 인덱스로 맵핑시켜주는 vocab 객체, 토큰화 함수, 전처리 등을 지정할 수 있다.\n",
    "- 예를 들어..\n",
    "> \"옷 색깔이 생각보다 너무 진해서 별로예요...\",'0'\n",
    "\n",
    "리뷰 문장과 (긍정/부정)을 분류하는 데이터셋이 있다면,\n",
    "1. TEXT\n",
    "2. LABEL\n",
    "- 위의 2개의 필드 객체를 생성해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "\n",
    "TEXT = Field(sequential=True,  # 순서가 있는 데이터인가?\n",
    "            use_vocab=True,  # vocab 객체를 사용할 것인가?\n",
    "            tokenize=str.split,  # 단어의 토크나이징을 맡아줄 함수. ex) konlpy 등 사용가능 \n",
    "            lower=True,  # 영어는 소문자로 만들어준다\n",
    "            batch_first=True)  # 배치 우선순위 올림 : 텐서 크기는 (배치, 문장 최대 길이) 로 만들어진다.\n",
    "\n",
    "LABEL = Field(sequential=False,\n",
    "             use_vocab=False,\n",
    "             preprocessing = lambda x: int(x),  # 라벨 데이터:디폴트 string -> int로 바꿔준다.\n",
    "             batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 데이터 세트 만들기 (Create Datasets)\n",
    "- 데이터 세트는 위에 지정한 필드에 기반하여 데이터를 불러온다.\n",
    "- 여기서 train, valid, text 세트를 나눠 불러온다. -> splits 메서드 사용\n",
    "- tabular -> table 형식의\n",
    "- fields 는 리스트 형태로 넣어준다.\n",
    "\n",
    "[(**'필드이름(내맘대로)'**, **필드객체(아까생성한거)**), (..)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "train_data = TabularDataset.splits(path='./data/',\n",
    "                                  train='train_path',\n",
    "                                  vaild='vaild_path',\n",
    "                                  test='test_path',\n",
    "                                  format='tsv',\n",
    "                                  fields=[('text', TEXT), ('label', LABEL)]\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Vocab 생성\n",
    "- 토큰과 index를 매칭시켜주는 단어장을 생성한다.\n",
    "- 디폴트: <unk> 0, <pad> 1\n",
    "- 필드 지정시, 문장 시작 토큰은 3, 끝 토큰은 4 로 할당된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 데이터 로더 만들기 (Create Data Loader)\n",
    "- 배치 사이즈 만큼 데이터를 불러올 로더를 만든다.\n",
    "- 데이터셋과 마찬가지로 train, vaild, test 나눠 불러올 수 있다.\n",
    "- 매 배치 때마다, 최대 길이에 따라 알아서 패딩 작업도 해준다. = input 길이를 같게 만들어 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator\n",
    "\n",
    "train_loader, vaild_loader, test_loader = Iterator.splits((train_data, vaild_data, test_data),\n",
    "                                                         batch_size =3,\n",
    "                                                         device=None,  # gpu 사용시, cuda 입력\n",
    "                                                         repear = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    breake\n",
    "print(batch.text)\n",
    "print(batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
